#### Papers

- Pretrained Language Models for Text Generation: A Survey
- Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training
- Pay Attention to MLPs
- EASE: Extractive-Abstractive Summarization with Explanations
- Poolingformer: Long Document Modeling with Pooling Attention
- FNet: Mixing Tokens with Fourier Transforms
- Self-Supervised Learning with Swin Transformers
- Are Pre-trained Convolutions Better than Pre-trained Transformers?
- Hierarchical Graph Neural Networks
- A Survey of Data Augmentation Approaches for NLP
- Language Modelling as a Multi-Task Problem

#### Blogs

- [KELM：知识图谱与语言模型预训练语料库的整合，将知识图谱转换为合成自然语言句子，以增强预训练语料库](https://ai.googleblog.com/2021/05/kelm-integrating-knowledge-graphs-with.html)
- [多任务统一模型(Multitask Unified Model，MUM)：信息理解的AI新里程碑，能理解语言，也能生成语言，多模态、跨语种，能比以前的模型更全面地理解信息和世界知识](https://blog.google/products/search/introducing-mum/amp/)
- [图神经网络(GNN)实战教程](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html)
- [ICLR 2021知识图谱相关进展总结](https://mgalkin.medium.com/knowledge-graphs-iclr-2021-6e0b52c80686)
- [Transformer解析：理解GPT-3, BERT, T5背后的模型](https://daleonai.com/transformers-explained)
- [交互可视化理解图卷积](https://drafts.distill.pub/ameya98/exploring-graph-nns/)

#### Educations

- [李宏毅2021春季机器学习课程课件及作业](https://github.com/Fafa-DL/Lhy_Machine_Learning)
- [Awesome Privacy：隐私保护相关资源的列表](https://github.com/pluja/awesome-privacy)
- [deep-probprog-course：深度概率编程课程资料](https://github.com/aleatory-science/deep-probprog-course)
- [RL4Recsys：强化学习推荐系统相关论文列表](https://github.com/henryslzhao/RL4Recsys)

#### Tools & Github

- [最新编程语言预训练模型(PL-PTMs)列表](https://github.com/yuewang-cuhk/awesome-programming-language-pretraining-papers)
- [LAS_Mandarin_PyTorch：端到端的中文语音识别](https://github.com/jackaduma/LAS_Mandarin_PyTorch)